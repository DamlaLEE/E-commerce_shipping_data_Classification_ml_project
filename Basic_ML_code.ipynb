{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9fb26f",
   "metadata": {},
   "source": [
    "# Basic ML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f702609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee63ab",
   "metadata": {},
   "source": [
    "##### ìƒê´€ê´€ê³„ ë¶„ì„ _Correlation\n",
    "\n",
    "<ğŸ“Š ìƒê´€ê´€ê³„ í•´ì„ ê¸°ì¤€í‘œ (Correlation Strength)>\n",
    "\n",
    "| ìƒê´€ê³„ìˆ˜ ë²”ìœ„       | í•´ì„ ë‚´ìš©         |\n",
    "|---------------------|------------------|\n",
    "| x â‰¤ 0.1             | ë§¤ìš° ì•½í•œ ìƒê´€ê´€ê³„ |\n",
    "| 0.1 < x â‰¤ 0.3       | ì•½í•œ ìƒê´€ê´€ê³„     |\n",
    "| 0.3 < x â‰¤ 0.5       | ì¤‘ê°„ ì •ë„ ìƒê´€ê´€ê³„ |\n",
    "| 0.5 < x â‰¤ 0.7       | ê°•í•œ ìƒê´€ê´€ê³„     |\n",
    "| 0.7 < x             | ë§¤ìš° ê°•í•œ ìƒê´€ê´€ê³„ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e85f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. correlation code\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#ver1.\n",
    "corr_feature1_all = df.corr(numeric_only=True)['faeture'].sort_values()\n",
    "\n",
    "#ver2.\n",
    "corr_feature1_by1 = df['feature'].corr(df['feature'])\n",
    "\n",
    "#ver3. pearsonr \n",
    "correlation, p_value = pearsoner(df[column1], df[columns2])\n",
    "print(correlation, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c48aee",
   "metadata": {},
   "source": [
    "##### Classification ML model _ fit & perdict\n",
    "\n",
    ">step1. encoding : one-hot encoding & Label Encoding  \n",
    "step2. ML modeling  \n",
    "step3. Hyper Parameter Tuning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98dfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. one-hot encoding\n",
    "# mapping \n",
    "gender = {'M':0, 'F':1}\n",
    "df['gender'] = df['gender'].map(gender)\n",
    "\n",
    "# pd.get_dummies\n",
    "df_encoding = pd.get_dummies(df_encoding, columns=['feature1', 'feature2'], dtpye=int)\n",
    "\n",
    "# 0. label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = ['Red', 'Orange', 'Blue']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdaf5f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraget\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# supervised learning's Label & result \u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[selected_features]\n\u001b[0;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target]\n\u001b[0;32m     24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## 1. Linear & Tree model code \n",
    "# 0. split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Linear model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 2. Tree model\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 3. score\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "selected_features = ['feature1', 'feature2']\n",
    "target = 'traget'\n",
    "\n",
    "# supervised learning's Label & result \n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# model class\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"SVC\" : SVC(),\n",
    "    \"RandomForest\" : RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"GradientBoosting\" : GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\" : XGBClassifier(n_estimators=100, random_state=42),\n",
    "    \"LightGBM\" : LGBMClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# model fit & predict & evaluation \n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train) #Label & result\n",
    "    y_pred = model.predice(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append((name, acc, recall, precision, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "# setting evaluation score\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# straitified K-fold\n",
    "cv = StratifiedKFold(n_split=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pre-tunning : Randomized search\n",
    "random_params = {\n",
    "    'n_estimators' : [100,200,300],\n",
    "    'max_depth' : [3,5,7],\n",
    "    'learning_rate' : np.linspace(0.01, 0.3, 1),\n",
    "    'min_child_samples' : [10, 20, 30],\n",
    "    'subsample' : [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree' : [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# ML Learning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=LGBMClassifier(random_state=42),\n",
    "    param_distributions=random_params,\n",
    "    n_iter=10,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1, #-1 GPU ë¯¸ì‚¬ìš©\n",
    ")\n",
    "\n",
    "random_search.fit(X,y)\n",
    "\n",
    "print(\"Randomized Search CV :\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf31263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final _ ML\n",
    "best_params = random_search.best_params_\n",
    "grid_params = {\n",
    "    'n_estimators' : [best_params['n_estimators']],\n",
    "    'max_depth' : [best_params['max_depth']],\n",
    "    'learning_rate' : [best_params['learning_rate']],\n",
    "    'min_child_samples' : [best_params['min_child_samples']],\n",
    "    'subsample' : [best_params['subsample']],\n",
    "    'colsample_bytree' : [best_params['colsample_bytree']],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = LGBMClassifier(random_state=42),\n",
    "    cv = cv,\n",
    "    param_grid = grid_params,\n",
    "    scoring = f1_scorer,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Grid Search Best Params:\", grid_search.best_params_)\n",
    "print(\"Best F1 score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "champion_model = model.best_estimator_\n",
    "\n",
    "with open(\"Champion_model_,,,.pkl\", 'wb') as filename:\n",
    "    pickle.dump(champion_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9a3c2",
   "metadata": {},
   "source": [
    "### ë¶€ê°€ ê¸°ëŠ¥ : future_importances_ & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Tree ëª¨ë¸ì—ì„œ ì‚¬ìš©ê°€ëŠ¥í•œ feature_importances\n",
    "\n",
    "model = model(n_estimators=100, random_stats=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "feature_name = X_train.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "                'feature' : feature_name,\n",
    "                'importance' : feature_importance.round(2),\n",
    "                }).set_index('feature').store_values(by='importance', ascending=False)\n",
    "\n",
    "### visualisation\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
    "plt.title(\"TOP 10 importance fatures in ___Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# í˜¼ë™í–‰ë ¬ : ì´ì§„ë¶„ë¥˜ ê¸°ë²•ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì˜ˆì¸¡ê²°ê³¼ë¥¼ ì‹¤ì œê°’ê³¼ ë¹„êµí•´ì„œ ë„¤ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆ”\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_Labels=[0,1])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix of Final Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9eb5b0",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "- ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì—ì„œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹¤ì œê°’ê³¼ ë¹„êµí•´ì„œ ë„¤ê°€ì§€ ë²”ì£¼ë¡œ ë‚˜ëˆ”\n",
    "\n",
    "|ì‹¤ì œ ê°’ / ì˜ˆì¸¡ê°’ |   0(ì˜ˆì¸¡)   |    1(ì‹¤ì œ)   |\n",
    "|----------------|------------|--------------|\n",
    "|    0 (ì‹¤ì œ)   | TN(true negative) | FP(false Positive) |\n",
    "|    1 (ì‹¤ì œ)   | FN(False negative) | TP(True positive) |\n",
    "\n",
    "0 = Negative(False), 1 = positive(True)\n",
    "\n",
    ">TP : ì§„ì§œ 1ì¸ë° 1ë¡œ ì˜ˆì¸¡ (ì •í™•ë„ ë†’ìŒ) : 1247  \n",
    "TN : ì§„ì§œ 0ì¸ì— 0ìœ¼ë¡œ ì˜ˆì¸¡ (ì •í™•ë„ ë†’ìŒ) : 1013  \n",
    "FP : ì‹¤ì œ 0 (ì§€ì—°) ì¸ë° 1 (ì •ì‹œë„ì°©)ë¡œ ì˜ˆì¸¡í—˜ (ì˜ˆì¸¡ì€ í‹€ë ¸ìœ¼ë‚˜ ê³ ê° ì…ì¥ì—ì„œëŠ” ì¢‹ìŒ_ì„œë¹„ìŠ¤ì— ì¢‹ì§€ë„ ë‚˜ì˜ì§€ë„ ì•ŠìŒ) : 975  \n",
    "FN : ì‹¤ì œ 1 (ì •ì‹œë„ì°©) ì¸ë° 0 (ì§€ì—°)ìœ¼ë¡œ ì˜ˆì¸¡ (ì˜ˆì¸¡ì´ í‹€ë ¸ê³  ê³ ê°ë„ ë¶€ì •ì ì¸ ê²½í—˜ì„ í•¨_ì„œë¹„ìŠ¤ì— ì¢‹ì§€ ì•ŠìŒ) : 65  \n",
    "\n",
    "+ ì •í™•ë„ëŠ” FPë¡œ ì¸í•´ì„œ ì¡°ê¸ˆ ë–¨ì–´ì¡Œìœ¼ë‚˜ ì„œë¹„ìŠ¤ì— ë¶€ì •ì ì¸ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” False negative ì˜ˆì¸¡ì´ ì ì—ˆìŒìœ¼ë¡œ í™œìš©í•  ê°€ì¹˜ê°€ ìˆëŠ” ëª¨ë¸ë¡œ ë³´ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27816d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2eb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8748b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
