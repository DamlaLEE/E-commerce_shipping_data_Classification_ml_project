{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9fb26f",
   "metadata": {},
   "source": [
    "# Basic ML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f702609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import missingno\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee63ab",
   "metadata": {},
   "source": [
    "##### ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Î∂ÑÏÑù _Correlation\n",
    "\n",
    "<üìä ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ Ìï¥ÏÑù Í∏∞Ï§ÄÌëú (Correlation Strength)>\n",
    "\n",
    "| ÏÉÅÍ¥ÄÍ≥ÑÏàò Î≤îÏúÑ       | Ìï¥ÏÑù ÎÇ¥Ïö©         |\n",
    "|---------------------|------------------|\n",
    "| x ‚â§ 0.1             | Îß§Ïö∞ ÏïΩÌïú ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ |\n",
    "| 0.1 < x ‚â§ 0.3       | ÏïΩÌïú ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ     |\n",
    "| 0.3 < x ‚â§ 0.5       | Ï§ëÍ∞Ñ Ï†ïÎèÑ ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ |\n",
    "| 0.5 < x ‚â§ 0.7       | Í∞ïÌïú ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ     |\n",
    "| 0.7 < x             | Îß§Ïö∞ Í∞ïÌïú ÏÉÅÍ¥ÄÍ¥ÄÍ≥Ñ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e85f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. correlation code\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#ver1.\n",
    "corr_feature1_all = df.corr(numeric_only=True)['faeture'].sort_values()\n",
    "\n",
    "#ver2.\n",
    "corr_feature1_by1 = df['feature'].corr(df['feature'])\n",
    "\n",
    "#ver3. pearsonr \n",
    "correlation, p_value = pearsoner(df[column1], df[columns2])\n",
    "print(correlation, p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c48aee",
   "metadata": {},
   "source": [
    "##### Classification ML model _ fit & perdict\n",
    "\n",
    ">step1. encoding : one-hot encoding & Label Encoding  \n",
    "step2. ML modeling  \n",
    "step3. Hyper Parameter Tuning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98dfad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. one-hot encoding\n",
    "# mapping \n",
    "gender = {'M':0, 'F':1}\n",
    "df['gender'] = df['gender'].map(gender)\n",
    "\n",
    "# pd.get_dummies\n",
    "df_encoding = pd.get_dummies(df_encoding, columns=['feature1', 'feature2'], dtpye=int)\n",
    "\n",
    "# 0. label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data = ['Red', 'Orange', 'Blue']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdaf5f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraget\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# supervised learning's Label & result \u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[selected_features]\n\u001b[0;32m     22\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target]\n\u001b[0;32m     24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "## 1. Linear & Tree model code \n",
    "# 0. split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Linear model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 2. Tree model\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# 3. score\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "selected_features = ['feature1', 'feature2']\n",
    "target = 'traget'\n",
    "\n",
    "# supervised learning's Label & result \n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# model class\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\" : LogisticRegression(),\n",
    "    \"SVC\" : SVC(),\n",
    "    \"RandomForest\" : RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"GradientBoosting\" : GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\" : XGBClassifier(n_estimators=100, random_state=42),\n",
    "    \"LightGBM\" : LGBMClassifier(n_estimators=100, random_state=42),\n",
    "}\n",
    "\n",
    "# model fit & predict & evaluation \n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train) #Label & result\n",
    "    y_pred = model.predice(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append((name, acc, recall, precision, f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "X = df[selected_features]\n",
    "y = df[target]\n",
    "\n",
    "# setting evaluation score\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "# straitified K-fold\n",
    "cv = StratifiedKFold(n_split=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Pre-tunning : Randomized search\n",
    "random_params = {\n",
    "    'n_estimators' : [100,200,300],\n",
    "    'max_depth' : [3,5,7],\n",
    "    'learning_rate' : np.linspace(0.01, 0.3, 1),\n",
    "    'min_child_samples' : [10, 20, 30],\n",
    "    'subsample' : [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree' : [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# ML Learning\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=LGBMClassifier(random_state=42),\n",
    "    param_distributions=random_params,\n",
    "    n_iter=10,\n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    "    n_jobs=-1, #-1 GPU ÎØ∏ÏÇ¨Ïö©\n",
    ")\n",
    "\n",
    "random_search.fit(X,y)\n",
    "\n",
    "print(\"Randomized Search CV :\", random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf31263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final _ ML\n",
    "best_params = random_search.best_params_\n",
    "grid_params = {\n",
    "    'n_estimators' : [best_params['n_estimators']],\n",
    "    'max_depth' : [best_params['max_depth']],\n",
    "    'learning_rate' : [best_params['learning_rate']],\n",
    "    'min_child_samples' : [best_params['min_child_samples']],\n",
    "    'subsample' : [best_params['subsample']],\n",
    "    'colsample_bytree' : [best_params['colsample_bytree']],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = LGBMClassifier(random_state=42),\n",
    "    cv = cv,\n",
    "    param_grid = grid_params,\n",
    "    scoring = f1_scorer,\n",
    "    verbose = 1,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Grid Search Best Params:\", grid_search.best_params_)\n",
    "print(\"Best F1 score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving\n",
    "champion_model = model.best_estimator_\n",
    "\n",
    "with open(\"Champion_model_,,,.pkl\", 'wb') as filename:\n",
    "    pickle.dump(champion_model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d9a3c2",
   "metadata": {},
   "source": [
    "### Î∂ÄÍ∞Ä Í∏∞Îä• : future_importances_ & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667bc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Tree Î™®Îç∏ÏóêÏÑú ÏÇ¨Ïö©Í∞ÄÎä•Ìïú feature_importances\n",
    "\n",
    "model = model(n_estimators=100, random_stats=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "feature_name = X_train.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "                'feature' : feature_name,\n",
    "                'importance' : feature_importance.round(2),\n",
    "                }).set_index('feature').store_values(by='importance', ascending=False)\n",
    "\n",
    "### visualisation\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=importance_df.head(10), x='importance', y='feature')\n",
    "plt.title(\"TOP 10 importance fatures in ___Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# ÌòºÎèôÌñâÎ†¨ : Ïù¥ÏßÑÎ∂ÑÎ•ò Í∏∞Î≤ïÏóêÏÑú ÏÇ¨Ïö©ÎêòÎäî ÏòàÏ∏°Í≤∞Í≥ºÎ•º Ïã§Ï†úÍ∞íÍ≥º ÎπÑÍµêÌï¥ÏÑú ÎÑ§Í∞ÄÏßÄ Î≤îÏ£ºÎ°ú ÎÇòÎàî\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_Labels=[0,1])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix of Final Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9eb5b0",
   "metadata": {},
   "source": [
    "##### Confusion Matrix\n",
    "- Ïù¥ÏßÑ Î∂ÑÎ•ò Î¨∏Ï†úÏóêÏÑú Î™®Îç∏Ïùò ÏòàÏ∏° Í≤∞Í≥ºÎ•º Ïã§Ï†úÍ∞íÍ≥º ÎπÑÍµêÌï¥ÏÑú ÎÑ§Í∞ÄÏßÄ Î≤îÏ£ºÎ°ú ÎÇòÎàî\n",
    "\n",
    "|Ïã§Ï†ú Í∞í / ÏòàÏ∏°Í∞í |   0(ÏòàÏ∏°)   |    1(Ïã§Ï†ú)   |\n",
    "|----------------|------------|--------------|\n",
    "|    0 (Ïã§Ï†ú)   | TN(true negative) | FP(false Positive) |\n",
    "|    1 (Ïã§Ï†ú)   | FN(False negative) | TP(True positive) |\n",
    "\n",
    "0 = Negative(False), 1 = positive(True)\n",
    "\n",
    ">TP : ÏßÑÏßú 1Ïù∏Îç∞ 1Î°ú ÏòàÏ∏° (Ï†ïÌôïÎèÑ ÎÜíÏùå) : 1247  \n",
    "TN : ÏßÑÏßú 0Ïù∏Ïóê 0ÏúºÎ°ú ÏòàÏ∏° (Ï†ïÌôïÎèÑ ÎÜíÏùå) : 1013  \n",
    "FP : Ïã§Ï†ú 0 (ÏßÄÏó∞) Ïù∏Îç∞ 1 (Ï†ïÏãúÎèÑÏ∞©)Î°ú ÏòàÏ∏°Ìóò (ÏòàÏ∏°ÏùÄ ÌãÄÎ†∏ÏúºÎÇò Í≥†Í∞ù ÏûÖÏû•ÏóêÏÑúÎäî Ï¢ãÏùå_ÏÑúÎπÑÏä§Ïóê Ï¢ãÏßÄÎèÑ ÎÇòÏÅòÏßÄÎèÑ ÏïäÏùå) : 975  \n",
    "FN : Ïã§Ï†ú 1 (Ï†ïÏãúÎèÑÏ∞©) Ïù∏Îç∞ 0 (ÏßÄÏó∞)ÏúºÎ°ú ÏòàÏ∏° (ÏòàÏ∏°Ïù¥ ÌãÄÎ†∏Í≥† Í≥†Í∞ùÎèÑ Î∂ÄÏ†ïÏ†ÅÏù∏ Í≤ΩÌóòÏùÑ Ìï®_ÏÑúÎπÑÏä§Ïóê Ï¢ãÏßÄ ÏïäÏùå) : 65  \n",
    "\n",
    "+ Ï†ïÌôïÎèÑÎäî FPÎ°ú Ïù∏Ìï¥ÏÑú Ï°∞Í∏à Îñ®Ïñ¥Ï°åÏúºÎÇò ÏÑúÎπÑÏä§Ïóê Î∂ÄÏ†ïÏ†ÅÏù∏ ÏòÅÌñ•ÏùÑ ÎØ∏ÏπòÎäî False negative ÏòàÏ∏°Ïù¥ Ï†ÅÏóàÏùåÏúºÎ°ú ÌôúÏö©Ìï† Í∞ÄÏπòÍ∞Ä ÏûàÎäî Î™®Îç∏Î°ú Î≥¥ÏûÑ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27816d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2eb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8748b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
